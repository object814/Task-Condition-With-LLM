<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Generalizable Long-Horizon Manipulations with Large Language Models">
  <title>Generalizable Long-Horizon Manipulations with Large Language Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./css/bulma.min.css">
  <link rel="stylesheet" href="./css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./css/bulma-slider.min.css">
  <link rel="stylesheet" href="./css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./js/fontawesome.all.min.js"></script>
  <script src="./js/bulma-carousel.min.js"></script>
  <script src="./js/bulma-slider.min.js"></script>
  <script src="./js/index.js"></script>
  <link rel="stylesheet" href="index.css">
<style>
  
</style>
</head>
<body>
<section class="hero">
  <div class="hero-body" style="background-color: white;">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title" style="width: 1200px; color: black;">Generalizable Long-Horizon Manipulations with
            Large Language Models</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Haoyu Zhou<sup>1</sup>,</span>
            <span class="author-block">
              Mingyu Ding<sup>2</sup>,</span>
            <span class="author-block">
              Weikun Peng<sup>1</sup>,</span>
            </span>
            <span class="author-block">
              Masayoshi Tomizuka<sup>2</sup>,</span>
            </span>
            <span class="author-block">
              Lin Shao<sup>1</sup>,</span>
            </span>
            <span class="author-block">
              Chuang Gan<sup>3,4</sup></span>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>National University of Singapore;</span>
            <span class="author-block"><sup>2</sup>UC Berkeley, USA;</span>
            <span class="author-block"><sup>3</sup>University of Massachusetts Amherst, USA;</span>
            <span class="author-block"><sup>4</sup>MIT-IBM Watson AI Lab, USA</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2310.02264"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2310.02264"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=TpCIRg9XuEg&ab_channel=object814"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
            </div>

      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            This work introduces a framework harnessing the capabilities of Large Language Models (LLMs) to generate primitive task conditions for 
            generalizable long-horizon manipulations with novel objects and unseen tasks. These task conditions serve as guides for the 
            generation and adjustment of Dynamic Movement Primitives (DMP) trajectories for longhorizon task execution. We further create a challenging robotic manipulation task suite 
            based on Pybullet for long-horizon task evaluation. 
            Extensive experiments in both simulated and realworld environments demonstrate the effectiveness of our framework on both familiar tasks involving new objects and novel but related tasks,
            highlighting the potential of LLMs in enhancing robotic system versatility and adaptability 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Framework Structure</h2>
          <div class="content has-text-justified">
            <p>
              We leverage LLMs to generate and generalize primitive task conditions for both familiar tasks with novel objects and novel but related tasks. 
              Subsequently, the highlevel task conditions guide the generation and adjustment of lowlevel trajectories originally learned from demonstrations for longhorizon task execution. 
            </p>
          </div>
          <div class="columns is-vcentered">
            <div class="column is-three-fifths has-text-centered">
              <video controls autoplay muted loop>  
                <source src="compressed/1.mp4" type="video/mp4">  
              </video>
            </div>
            <div class="column is-two-fifths has-text-centered">
              <img src="compressed/2.png"/>
            </div>
          </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="columns is-full-width">
        <div class="column is-three-fifths ">
          <h2 class="title is-3">Task condition generation and generalization experiment</h2>
          <p class="has-text-justified">
            We evaluate the ability of our framework to generate and generalize task conditions on all 10 primitive tasks. 
            The LLM (GPT-3.5) is provided with condition examples. Comparison is made with task conditions generated from environments (methods explained in paper). 
            A successfully generated task condition should contain accurate and enough information to guide the execution of the primitive task.
          </p>
        </div>
        <div class="column is-two-fifths has-text-centered">
          <img src="compressed/3.png"/>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="columns is-full-width">
        <div class="column is-three-fifths">
          <h2 class="title is-3">Simulation experiment</h2>
          <p class="has-text-justified">
            To evaluate our framework's ability to execute long-horizon tasks using DMP trajectories generated and adjuested by task conditions, we design a challenging Robotic Manipulation Task Suite in Pybullet. 
          </p>
          <p class="has-text-justified">
            The environment consists of two 7 Dof robots Franka and Kinova with a kitchen scene including various interactive objects. 
            It contains 10 diverse primitive tasks (37 if considering different objects) and 4 long-horizon tasks in simulation. 
          </p>
        </div>
        <div class="column is-two-fifths has-text-centered">
          <img src="compressed/4.png"/>
        </div>
      </div>
    </div>
  </div>
  <br><br>
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="columns is-full-width">
        <div class="column is-half has-text-centered">
          <video controls autoplay muted loop>  
            <source src="compressed/5.mp4" type="video/mp4">  
          </video>
          <p class="has-text-centered">
            Demonstration: Put the bowl into the bottom drawer
          </p>
        </div>
        <div class="column is-half has-text-centered">
          <video controls autoplay muted loop>  
            <source src="compressed/6.mp4" type="video/mp4">  
          </video>
          <p class="has-text-centered">
            Generation and execution: Put the bowl into the upper drawer
          </p>
        </div>
      </div>
    </div>
  </div>
  <br><br><br>
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="columns is-full-width">
        <div class="column is-half has-text-centered">
          <video controls autoplay muted loop>  
            <source src="compressed/7.mp4" type="video/mp4">  
          </video>
          <p class="has-text-centered">
            Demonstration: Put the bottle into the box
          </p>
        </div>
        <div class="column is-half has-text-centered">
          <video controls autoplay muted loop>  
            <source src="compressed/8.mp4" type="video/mp4">  
          </video>
          <p class="has-text-centered">
            Generation and execution: Put the bowl into the box
          </p>
        </div>
      </div>
    </div>
  </div>
  <br><br><br>
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="columns is-full-width">
        <div class="column is-two-fifths has-text-centered">
          <video controls autoplay muted loop>  
            <source src="compressed/9.mp4" type="video/mp4">  
          </video>
          <h3 class="title is-6">Move the bottle into the box w/o task condition <br><br></h3>
          <p class="has-text-centered">
            The move into primitive task is failed because initial goal position obtained from environment pointcloud is deviated. 
            And a collision between bottle and box happened.
          </p>
        </div>
        <div class="column is-two-fifths has-text-centered">
          <video controls autoplay muted loop>  
            <source src="compressed/10.mp4" type="video/mp4">  
          </video>
          <h3 class="title is-6">Move the bottle into the box w/ task condition adjusting trajectory</h3>
          <p class="has-text-centered">
            As the collision between bottle and box is against task condition collision, 
            the manipulator backwards a few steps and adjust goal position to generate a new DMP trajectory, 
            eventually complete the task.
          </p>
        </div>
        <div class="column is-5">
          <h3 class="title is-6">Task condition by LLM </h3>
          <p>
            <strong>Task name:</strong> move bottle into box<br>
            <strong>Relevant objects:</strong><br>
            bottle, box, gripper<br>
            <strong>Pre-conditions:</strong><br>
            gripper grasping bottle<br>
            box open<br>
            <strong>Post-conditions:</strong><br>
            gripper grasping bottle<br>
            bottle inside box<br>
            box open<br>
            <strong>Collisions:</strong><br>
            gripper and bottle
          </p>
        </div>
      </div>
    </div>
  </div>

  <br><br>
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="columns is-full-width">
        <div class="column is-two-fifths has-text-centered">
          <video controls autoplay muted loop>  
            <source src="compressed/11.mp4" type="video/mp4">  
          </video>
          <h3 class="title is-6">Grasp the bottle w/o task condition <br><br></h3>
          <p class="has-text-centered">
            The move into primitive task is failed because initial goal position obtained from environment pointcloud is deviated. 
            And a collision between bottle and box happened.
          </p>
        </div>
        <div class="column is-two-fifths has-text-centered">
          <video controls autoplay muted loop>  
            <source src="compressed/12.mp4" type="video/mp4">  
          </video>
          <h3 class="title is-6">Grasp the bottle w/  task condition <br> generating trajectory</h3>
          <p class="has-text-centered">
            As the collision between bottle and box is against task condition collision, 
            the manipulator backwards a few steps and adjust goal position to generate a new DMP trajectory, 
            eventually complete the task.
          </p>
        </div>
        <div class="column is-5">
          <h3 class="title is-6">Task condition by LLM </h3>
          <p>
            <strong>Task name:</strong> grasp bottle<br>
            <strong>Relevant objects:</strong><br>
            bottle, gripper<br>
            <strong>Pre-conditions:</strong><br>
            gripper not grasping<br>
            <strong>Post-conditions:</strong><br>
            gripper grasping bottle<br>
            <strong>Collisions:</strong><br>
            gripper and bottle
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Real-world experiment</h2>
          <div class="content has-text-justified">
            <p>
              To demonstrate the practicality of our to perform longhorizon tasks in real scenarios, we set up a real-world long-horizon task, 
              featuring a dual-arm MOVO robot which has two 7 DoF manipulators and a Kinect RGB-D camera overhead. 
              We use Segment Anything to obtain segmented point clouds of the surroundings and objects. 
              Position control is performed as we use rangeIK for solving inverse kinematics.
            </p>
          </div>
          <div class="columns is-vcentered">
            <div class="column is-three-fifths">
              <video controls autoplay muted loop>  
                <source src="compressed/13.mp4" type="video/mp4">  
              </video>
            </div>
            <div class="column is-two-fifths">
              <p>
                ■&nbsp;&nbsp;grasp the bottle;<br>
                ■&nbsp;&nbsp;open the microwave;<br>
                ■&nbsp;&nbsp;move the bottle in front of the microwave;<br>
                ■&nbsp;&nbsp;move the bottle into the microwave:<br>
                ■&nbsp;&nbsp;release the bottle;<br>
                ■&nbsp;&nbsp;move out of the microwave;<br>
                ■&nbsp;&nbsp;close the microwave.<br>
              </p>
            </div>
          </div>
      </div>
    </div>
  </div>

  <br><br><br>
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="columns is-full-width">
        <div class="column is-two-fifths has-text-centered">
          <video controls autoplay muted loop>  
            <source src="compressed/14.mp4" type="video/mp4">  
          </video>
          <h3 class="title is-6">Move the bottle into the microwave w/o task condition <br><br></h3>
        </div>
        <div class="column is-two-fifths has-text-centered">
          <video controls autoplay muted loop>  
            <source src="compressed/15.mp4" type="video/mp4">  
          </video>
          <h3 class="title is-6">Move the bottle into the microwave w/ task condition adjusting trajectory</h3>
        </div>
        <div class="column is-5">
          <h3 class="title is-6">Task condition by LLM </h3>
          <p>
            <strong>Task name:</strong> move bottle into microwave<br>
            <strong>Relevant objects:</strong><br>
            bottle, microwave, gripper<br>
            <strong>Pre-conditions:</strong><br>
            gripper grasping bottle<br>
            microwave open<br>
            <strong>Post-conditions:</strong><br>
            gripper grasping bottle<br>
            bottle inside microwave<br>
            microwave open<br>
            <strong>Collisions:</strong><br>
            gripper and bottle
          </p>
        </div>
      </div>
    </div>
  </div>

  <br><br>
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="columns is-full-width">
        <div class="column is-two-fifths has-text-centered">
          <video controls autoplay muted loop>  
            <source src="compressed/16.mp4" type="video/mp4">  
          </video>
          <h3 class="title is-6">Grasp the bottle w/o task condition <br><br></h3>
        </div>
        <div class="column is-two-fifths has-text-centered">
          <video controls autoplay muted loop>  
            <source src="compressed/17.mp4" type="video/mp4">  
          </video>
          <h3 class="title is-6">Grasp the bottle w/  task condition <br> generating trajectory</h3>
        </div>
        <div class="column is-5">
          <h3 class="title is-6">Task condition by LLM </h3>
          <p>
            <strong>Task name:</strong> right grasp bottle<br>
            <strong>Relevant objects:</strong><br>
            bottle, right gripper<br>
            <strong>Pre-conditions:</strong><br>
            right gripper not grasping<br>
            <strong>Post-conditions:</strong><br>
            right gripper grasping bottle<br>
            <strong>Collisions:</strong><br>
            right gripper and bottle
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <p>
      ICRA2024 submittion: Generalizable Long-Horizon Manipulations with Large Language Models 
    </p>
  </div>
</footer>

</body>
</html>
